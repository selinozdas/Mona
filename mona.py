# -*- coding: utf-8 -*-
"""selin(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17_eVt28SluHB_hQNwNlwvH2KqPftxkh3
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import shuffle
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, BatchNormalization, Dropout
from keras import optimizers
# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras
import pandas as pd

# First, look at everything.
from subprocess import check_output
print(check_output(["ls", "../input"]).decode("utf8"))

def load_images(path):
    # Put files into lists and return them as one list of size 4
    image_files = sorted([os.path.join(path, 'train_2', file) for file in os.listdir(path + "/train_2") if file.endswith('.jpg')])
    return image_files

#Load the images (path names)
path = "../input"
image_files = load_images(path)
len(image_files)

cor_img = "../input/train_2/95347.jpg"
cor_img in image_files

# Display one image
def display_one(a, title1 = "Original"):
    plt.imshow(a), plt.title(title1)
    plt.xticks([]), plt.yticks([])
    plt.show()
    
# Display two images
def display(a, b, title1 = "Original", title2 = "Edited"):
    plt.subplot(121), plt.imshow(a), plt.title(title1)
    plt.xticks([]), plt.yticks([])
    plt.subplot(122), plt.imshow(b), plt.title(title2)
    plt.xticks([]), plt.yticks([])
    plt.show()

#Load image
img = cv2.imread(image_files[20], cv2.IMREAD_UNCHANGED)
#Display image
display_one(img)

def scale_size(img, width=220, height=220):
    dim = (width, height)
    res_img = cv2.resize(img, dim, interpolation=cv2.INTER_LINEAR)
    return res_img

#Load image
img = cv2.imread(image_files[40], cv2.IMREAD_UNCHANGED)
#Resize image
res_img = scale_size(img, 100, 100)
#Display image
display(img, res_img)

print(img.shape)
print(res_img.shape)

#Load image
img = cv2.imread(image_files[100], cv2.IMREAD_UNCHANGED)

#Remove noise
no_noise_img = cv2.GaussianBlur(img, (5, 5), 0)

#Display them
display(img, no_noise_img, 'Original', 'Blurred')

#Normalize color
def normalize_color(img):
    b = img[:,:,0]
    g = img[:,:,1]
    r = img[:,:,2]
    
    total = b+g+r
    norm_img = np.zeros(img.shape,np.float32)
    norm_img[:,:,0] = b/total * 255.0
    norm_img[:,:,1] = b/total * 255.0
    norm_img[:,:,2] = b/total * 255.0
    
    return cv2.convertScaleAbs(norm_img)

#Load image
img = cv2.imread(image_files[10], cv2.IMREAD_UNCHANGED)

#Normalize color
norm_img = cv2.normalize(img, None, 0, 255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC3)
#norm_img = normalize_color(img)

#Display them
display(img, norm_img, 'Original', 'Normalized')

def preprocess_image(img_name, width, height):
    img = cv2.imread(img_name, cv2.IMREAD_UNCHANGED)
    res_img = scale_size(img, width, height)
    no_noise_img = cv2.GaussianBlur(res_img, (5, 5), 0)
    norm_img = cv2.normalize(no_noise_img, None, 0, 255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC3)
    norm_img = norm_img
    return norm_img

#Preprocess image
img = cv2.imread(image_files[75], cv2.IMREAD_UNCHANGED)
processed_img = preprocess_image(image_files[75], 100, 100)

#Display them
display(img, processed_img, 'Original', 'Processed')

processed_img.shape

train_info = pd.read_csv('../input/train_info.csv')

def get_info(image_file, train_info):
    image_file_name = image_file[17:]
    return train_info[train_info['filename'] == image_file_name]

def get_info_all(image_files, train_info):
    image_file_names = [image_file[17:] for image_file in image_files]
    return train_info[train_info['filename'].isin(image_file_names)]

def clean_nans(train_info):
    return train_info.dropna(subset=['style','genre'])

#info = get_info(image_files[10], train_info)
train2_info = clean_nans(get_info_all(image_files, train_info)) 
print(train2_info.shape)

#Look at genre and style classes
genre = set(train2_info['genre'])
style = set(train2_info['style'])

print("Genres")
for g in genre:
    print(g)
print("Styles")
for s in style:
    print(s)

print(len(genre))
print(len(style))

"""**Genre Classification**"""

width = 50
height = 50
train_size = train2_info.shape[0]
X = []
shapes = set()
del_names = []
#X = np.zeros((train_size, width, height, 3 ))
for i in range(train_size):
    result = preprocess_image("../input/train_2/"+train2_info['filename'].values[i], width, height)
    if result.shape != (width, height, 3):
        del_names.append(train2_info['filename'].values[i])
    else:
        X.append(result)
    #X[i,:,:,:] = preprocess_image("../input/train_2/"+train2_info['filename'].values[i], width, height)
#X = np.array(X)

#Delete the rows of del_names
new_train_info = train2_info[~train2_info['filename'].isin(del_names)]

len(new_train_info)

#Look at genre and style classes
genre = set(new_train_info['genre'])
style = set(new_train_info['style'])
print(len(genre))
print(len(style))

#Load data
new_X = np.array(X)
y = new_train_info['genre'].values

#Shuffle data
new_X, y = shuffle(new_X, y)

#One hot encoding
encoder = LabelEncoder()
encoder.fit(y)
encoded_y = np_utils.to_categorical(encoder.transform(y))

#Train-test split
X_train, X_test, y_train, y_test = train_test_split(new_X, encoded_y, test_size=0.33, random_state=42)

encoder.classes_

model = Sequential()
from keras.regularizers import l1
model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(width,height,3)))
model.add(MaxPooling2D(pool_size=(3, 3)))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(width,height,3)))
model.add(MaxPooling2D(pool_size=(3, 3)))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Conv2D(64, kernel_size=(3,3), activation='relu', input_shape=(width,height,3)))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Flatten())
model.add(Dense(32, activation='relu', activity_regularizer=l1(0.001)))
model.add(BatchNormalization())
model.add(Dropout(0.25))
model.add(Dense(40, activation='softmax', activity_regularizer=l1(0.001)))
model.summary()

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history =  model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50)

import matplotlib.pyplot as plt

loss = history.history['loss']

val_loss = history.history['val_loss']

epochs = range(1, len(loss) + 1)

plt.plot(epochs, loss, 'bo', label='Training loss')

plt.plot(epochs, val_loss, 'b', label='Validation loss')

plt.title('Training and validation accuracy')

plt.xlabel('Epochs')

plt.ylabel('Loss')

plt.legend()

plt.show()

import matplotlib.pyplot as plt

loss = history.history['acc']

val_loss = history.history['val_acc']

epochs = range(1, len(loss) + 1)

plt.plot(epochs, loss, 'bo', label='Training acc')

plt.plot(epochs, val_loss, 'b', label='Validation acc')

plt.title('Training and validation accuracy')

plt.xlabel('Epochs')

plt.ylabel('Loss')

plt.legend()

plt.show()